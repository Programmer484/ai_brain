add_info.txt   –   CLI Text-Ingestion MVP (LLM-powered)
==================================================================
Purpose: add a minimal terminal interface (`log` command) that
uses an LLM to decide the target database, pick a tag, and check
for “Why” (knowledge DB).  Saves the entry to Notion and prints
a success message.  Includes *real* unit tests (no smoke test).

------------------------------------------------------------------
Directory & file checklist
------------------------------------------------------------------
1. ai/intent.py
   • `def classify(text: str) -> dict`
       Returns:
         {
           "db": "health" | "knowledge",
           "tag": str,                # must be in predefined list
           "needs_why": bool          # true if db=="knowledge" and
                                       #   explanation clause missing
         }
   • Calls OpenAI (or configured LLM) with a prompt that:
       – Chooses db based on content,
       – Picks best tag from constants,
       – Detects explicit “why” clause.
   • Uses `config.OPENAI_API_KEY`, model name from config.

2. ai/predefined_tags.py
   • Constants:
       KNOWLEDGE_TAGS = ["Actionable", "Reference", "Idea", "Misc"]
       HEALTH_TAGS    = ["Sleep", "Mood", "Exercise", "Diet", "Misc"]

3. ingest/cli.py
   • Argparse CLI with one sub-command: `log`
     Usage: `python main.py log "your text here"`
   • Steps:
       1. Pass raw text to `ai.intent.classify`.
       2. If `needs_why` is True, prompt user (`input()`) and append
          `\nWhy: {answer}` to the text.
       3. Save via the appropriate DB module:
            – Knowledge: title=text[:50], why/extracted, tags=[tag]
            – Health:    log=text, tags=[tag]
       4. Print: `✅ Saved to {db} with tag “{tag}”.`

4. ingest/__init__.py
   • Empty for now.

5. main.py
   • Routes `sys.argv[1] == "log"` to `ingest.cli.main()`.

------------------------------------------------------------------
Implementation steps (commit after each)
------------------------------------------------------------------
0. Ensure backend layer (`db/knowledge.py`, `db/health.py`) exists.
1. Implement **ai/intent.py** with OpenAI call and JSON-style output.
2. Implement **ingest/cli.py** as described.
3. Update **main.py** delegation.

------------------------------------------------------------------
Testing (real unit tests)
------------------------------------------------------------------
tests/test_intent.py
   • Monkey-patch `openai.ChatCompletion.create` to return a fixed
     response JSON → assert classify() returns correct dict.

tests/test_cli.py
   • Monkey-patch `ai.intent.classify` to a stub returning:
       {"db":"health","tag":"Sleep","needs_why":False}
   • Run `ingest.cli.main()` via `subprocess` or direct call and
     assert that `db.health.create()` is invoked with expected args
     (use `unittest.mock.patch`).

These tests are **real** unit tests: they assert logic, not just exit
codes, yet avoid network calls by mocking the LLM.

------------------------------------------------------------------
Workflow & CI
------------------------------------------------------------------
• Existing CI already installs deps and runs tests; unit tests pass
  without external API calls thanks to monkey-patching.
• Add `OPENAI_API_KEY` to `.env.example`; CI need not supply it.

------------------------------------------------------------------
Environment variable reference (update .env.example)
------------------------------------------------------------------
NOTION_TOKEN=your_notion_token_here
KNOWLEDGE_DB_ID=your_knowledge_database_id_here
HEALTH_DB_ID=your_health_database_id_here
OPENAI_API_KEY=your_openai_key_here

------------------------------------------------------------------
Rules & notes
------------------------------------------------------------------
• No keyword heuristics—LLM decides db and tag.
• Predefined tag lists are authoritative; classifier must choose one
  or fallback to "Misc".
• No Telegram bot in this phase.
• If Notion raises an error, print the error and abort save.
• Keep code minimal; no extra abstractions beyond files listed here.

------------------------------------------------------------------
End of text_ingestion_plan.txt
------------------------------------------------------------------
